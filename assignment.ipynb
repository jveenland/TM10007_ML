{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7SXpaKwwGe5x"
   },
   "source": [
    "# TM10007 Assignment template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "CiDn2Sk-VWqE",
    "outputId": "64224cd2-6054-4b04-a3f6-af8290400dfc"
   },
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/jveenland/tm10007_ml.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and cleaning\n",
    "\n",
    "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NE_fTbKGe5z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of samples: 115\n",
      "The number of columns: 494\n",
      "The number of liposarcoma in the dataset: 58\n",
      "The number of lipoma in the dataset: 57\n"
     ]
    }
   ],
   "source": [
    "# Data loading functions. Uncomment the one you want to use\n",
    "# Import other classifiers you plan to use\n",
    "from worclipo.load_data import load_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "data = load_data()\n",
    "print(f\"The number of samples: {len(data.index)}\")\n",
    "print(f\"The number of columns: {len(data.columns)}\")\n",
    "print(f\"The number of liposarcoma in the dataset: {len(data[data['label'] == 'liposarcoma'])}\")\n",
    "print(f\"The number of lipoma in the dataset: {len(data[data['label'] == 'lipoma'])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aantal 0's per feature:\n",
      " label                                                       0\n",
      "PREDICT_original_sf_compactness_avg_2.5D                    0\n",
      "PREDICT_original_sf_compactness_std_2.5D                    0\n",
      "PREDICT_original_sf_rad_dist_avg_2.5D                       0\n",
      "PREDICT_original_sf_rad_dist_std_2.5D                       0\n",
      "                                                         ... \n",
      "PREDICT_original_phasef_phasesym_peak_position_WL3_N5     115\n",
      "PREDICT_original_phasef_phasesym_range_WL3_N5               0\n",
      "PREDICT_original_phasef_phasesym_energy_WL3_N5              0\n",
      "PREDICT_original_phasef_phasesym_quartile_range_WL3_N5     12\n",
      "PREDICT_original_phasef_phasesym_entropy_WL3_N5             0\n",
      "Length: 494, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def find_zeros_in_data(data):\n",
    "    # Maak een kopie van de data om de originele data niet te wijzigen\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # Vervang waarden die gelijk zijn aan 0 met NaN om ze gemakkelijk te tellen\n",
    "    data_copy = data_copy.replace(0, np.nan)\n",
    "    \n",
    "    # Tel het aantal NaNs in elke kolom, wat overeenkomt met het originele aantal 0's\n",
    "    zeros_count = data_copy.isna().sum()\n",
    "    \n",
    "    # Print het aantal 0's gevonden in elke kolom\n",
    "    print(\"Aantal 0's per feature:\\n\", zeros_count)\n",
    "    \n",
    "    # Return het aantal 0's per feature voor verdere analyse indien nodig\n",
    "    return zeros_count\n",
    "\n",
    "# Roep de functie aan met je dataset 'data'\n",
    "zeros_count = find_zeros_in_data(data)\n",
    "\n",
    "# # Vervang 0-waarden door NaN zodat de imputer ze kan identificeren\n",
    "# data.replace(0, np.nan, inplace=True)\n",
    "\n",
    "# # Initialiseer de imputer om de gemiddelde waarde ('mean') te gebruiken\n",
    "# imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "\n",
    "# # Pas de imputer toe op de data\n",
    "# # Dit vervangt elke NaN (oorspronkelijk 0) door het gemiddelde van de betreffende feature\n",
    "# data_imputed = pd.DataFrame(imputer.fit_transform(data), columns=data.columns)\n",
    "\n",
    "# # Controleer de eerste paar rijen van de aangepaste data\n",
    "# print(data_imputed.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (92, 493)\n",
      "Testing set size: (23, 493)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_and_split_data(csv_path, target_col, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Load dataset from a CSV file and split into training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "    - csv_path: str, path to the CSV file.\n",
    "    - target_col: str, name of the target variable column.\n",
    "    - test_size: float, proportion of the dataset to include in the test split (default is 0.2).\n",
    "    - random_state: int, controls the shuffling applied to the data before applying the split (default is 42).\n",
    "    \n",
    "    Returns:\n",
    "    - X_train: DataFrame, training set features.\n",
    "    - X_test: DataFrame, testing set features.\n",
    "    - y_train: Series, training set target.\n",
    "    - y_test: Series, testing set target.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Separate features and target variable\n",
    "    x = df.drop(['label', 'ID'], axis=1)\n",
    "    y = df[target_col]\n",
    "    \n",
    "    # Split the dataset into training and testing sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "csv_path = '/Users/anneloormemelink/Documents/Machine learning/TM10007_ML_Project_G17/worclipo/Lipo_radiomicFeatures.csv'  # Adjust this path to your CSV file's location\n",
    "target_col = 'label'  # Replace 'Target' with the actual name of your target column\n",
    "test_size = 0.2  # 20% of the data will be used for testing\n",
    "\n",
    "# Call the function\n",
    "x_train, x_test, y_train, y_test = load_and_split_data(csv_path, target_col, test_size)\n",
    "\n",
    "# Optionally, print the sizes of the splits to verify\n",
    "print(\"Training set size:\", x_train.shape)\n",
    "print(\"Testing set size:\", x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaler from sklearn, fitted on train data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_train)\n",
    "\n",
    "# Applying scaler to train and test set\n",
    "X_train_scaled = scaler.transform(x_train)\n",
    "X_test_scaled = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
